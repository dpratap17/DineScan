{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43df9058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Yes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m     13\u001b[0m X \u001b[38;5;241m=\u001b[39m data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspicy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreamy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_fruits\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m---> 14\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     16\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory_cluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mfit_predict(X_scaled)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:806\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:841\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    840\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 841\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    849\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Yes'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Perform clustering to group similar items (categories) together\n",
    "# We'll use KMeans for this example\n",
    "scaler = StandardScaler()\n",
    "X = data[['spicy', 'creamy', 'contains_fruits']]\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "data['category_cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Train a classification model to predict customer feedback based on features\n",
    "X = data.drop(columns=['feedback'])\n",
    "y = data['feedback']\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions to identify items with low feedback ratings\n",
    "data['predicted_feedback'] = model.predict(X)\n",
    "\n",
    "# Find frequent itemsets using association rule mining\n",
    "frequent_itemsets = apriori(data[['category', 'flavor', 'age_group']], min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Generate association rules to find relationships between items\n",
    "association_rules = association_rules(frequent_itemsets, metric='lift', min_threshold=1)\n",
    "\n",
    "# Suggestions for the owner\n",
    "# Find categories with low feedback ratings\n",
    "categories_to_remove = data[data['predicted_feedback'] < 4]['category'].unique()\n",
    "\n",
    "# Find flavors that are liked in different age groups\n",
    "flavors_by_age_group = data.groupby(['flavor', 'age_group'])['feedback'].mean().reset_index()\n",
    "\n",
    "# Find frequent associations between food items\n",
    "frequent_associations = association_rules[['antecedents', 'consequents', 'lift']]\n",
    "\n",
    "print(\"Categories to remove:\", categories_to_remove)\n",
    "print(\"Flavors liked by age group:\")\n",
    "print(flavors_by_age_group)\n",
    "print(\"Frequent associations between food items:\")\n",
    "print(frequent_associations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f49679d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Using cached mlxtend-0.22.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from mlxtend) (1.22.4)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from mlxtend) (3.5.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from mlxtend) (1.0.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from mlxtend) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\adity\\anaconda3\\lib\\site-packages (from mlxtend) (61.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3be8891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Yes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m     20\u001b[0m X \u001b[38;5;241m=\u001b[39m data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspicy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreamy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_fruits\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m---> 21\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     23\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory_cluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mfit_predict(X_scaled)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:806\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:841\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    840\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 841\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    849\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Yes'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Convert 'age' and 'rating' to ordinal integers\n",
    "age_mapping = {'less than 20': 1, '20 to 30': 2, '30 to 40': 3, '40 to 50': 4, '50 to 60': 5, 'greater than 60': 6}\n",
    "rating_mapping = {'1': 1, '2': 2, '3': 3, '4': 4, '5': 5}\n",
    "data['age'] = data['age'].map(age_mapping)\n",
    "data['feedback'] = data['feedback'].astype(str)  # Convert to string first to handle NaNs\n",
    "data['feedback'] = data['feedback'].map(rating_mapping)\n",
    "\n",
    "# Perform clustering to group similar items (categories) together\n",
    "# We'll use KMeans for this example\n",
    "scaler = StandardScaler()\n",
    "X = data[['spicy', 'creamy', 'contains_fruits']]\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "data['category_cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Train a classification model to predict customer feedback based on features\n",
    "X = data.drop(columns=['feedback'])\n",
    "y = data['feedback']\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions to identify items with low feedback ratings\n",
    "data['predicted_feedback'] = model.predict(X)\n",
    "\n",
    "# Find frequent itemsets using association rule mining\n",
    "frequent_itemsets = apriori(data[['category', 'flavor', 'age_group']], min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Generate association rules to find relationships between items\n",
    "association_rules = association_rules(frequent_itemsets, metric='lift', min_threshold=1)\n",
    "\n",
    "# Suggestions for the owner\n",
    "# Find categories with low feedback ratings\n",
    "categories_to_remove = data[data['predicted_feedback'] < 4]['category'].unique()\n",
    "\n",
    "# Find flavors that are liked in different age groups\n",
    "flavors_by_age_group = data.groupby(['flavor', 'age_group'])['feedback'].mean().reset_index()\n",
    "\n",
    "# Find frequent associations between food items\n",
    "frequent_associations = association_rules[['antecedents', 'consequents', 'lift']]\n",
    "\n",
    "print(\"Categories to remove:\", categories_to_remove)\n",
    "print(\"Flavors liked by age group:\")\n",
    "print(flavors_by_age_group)\n",
    "print(\"Frequent associations between food items:\")\n",
    "print(frequent_associations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09955b18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\anaconda3\\lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The allowed values for a DataFrame are True, False, 0, 1. Found value 26",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_feedback\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Find frequent itemsets using association rule mining\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m frequent_itemsets \u001b[38;5;241m=\u001b[39m \u001b[43mapriori\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmajor_flavor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_support\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_colnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Generate association rules to find relationships between items\u001b[39;00m\n\u001b[0;32m     37\u001b[0m association_rules \u001b[38;5;241m=\u001b[39m association_rules(frequent_itemsets, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlift\u001b[39m\u001b[38;5;124m'\u001b[39m, min_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlxtend\\frequent_patterns\\apriori.py:241\u001b[0m, in \u001b[0;36mapriori\u001b[1;34m(df, min_support, use_colnames, max_len, verbose, low_memory)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_support \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`min_support` must be a positive \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber within the interval `(0, 1]`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m min_support\n\u001b[0;32m    239\u001b[0m     )\n\u001b[1;32m--> 241\u001b[0m \u001b[43mfpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_input_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# DataFrame with SparseArray (pandas >= 0.24)\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:132\u001b[0m, in \u001b[0;36mvalid_input_check\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    127\u001b[0m val \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;28mtuple\u001b[39m(loc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m loc \u001b[38;5;129;01min\u001b[39;00m idxs)]\n\u001b[0;32m    128\u001b[0m s \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe allowed values for a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m are True, False, 0, 1. Found value \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (val)\n\u001b[0;32m    131\u001b[0m )\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(s)\n",
      "\u001b[1;31mValueError\u001b[0m: The allowed values for a DataFrame are True, False, 0, 1. Found value 26"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Perform label encoding for all non-numeric columns\n",
    "label_encoder = LabelEncoder()\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object' and column not in ['age', 'feedback']:\n",
    "        data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Perform clustering to group similar items (categories) together\n",
    "# We'll use KMeans for this example\n",
    "scaler = StandardScaler()\n",
    "X = data.drop(columns=['age', 'feedback'])\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "data['category_cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Train a classification model to predict customer feedback based on features\n",
    "X = data.drop(columns=['feedback'])\n",
    "y = data['feedback']\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions to identify items with low feedback ratings\n",
    "data['predicted_feedback'] = model.predict(X)\n",
    "\n",
    "# Find frequent itemsets using association rule mining\n",
    "frequent_itemsets = apriori(data[['category', 'major_flavor', 'age']], min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Generate association rules to find relationships between items\n",
    "association_rules = association_rules(frequent_itemsets, metric='lift', min_threshold=1)\n",
    "\n",
    "# Suggestions for the owner\n",
    "# Find categories with low feedback ratings\n",
    "categories_to_remove = data[data['predicted_feedback'] < 4]['category'].unique()\n",
    "\n",
    "# Find flavors that are liked in different age groups\n",
    "flavors_by_age_group = data.groupby(['flavor', 'age_group'])['feedback'].mean().reset_index()\n",
    "\n",
    "# Find frequent associations between food items\n",
    "frequent_associations = association_rules[['antecedents', 'consequents', 'lift']]\n",
    "\n",
    "print(\"Categories to remove:\", categories_to_remove)\n",
    "print(\"Flavors liked by age group:\")\n",
    "print(flavors_by_age_group)\n",
    "print(\"Frequent associations between food items:\")\n",
    "print(frequent_associations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33fc6f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\anaconda3\\lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The allowed values for a DataFrame are True, False, 0, 1. Found value 7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_feedback\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Find frequent itemsets using association rule mining\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m frequent_itemsets \u001b[38;5;241m=\u001b[39m \u001b[43mapriori\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmajor_flavor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_support\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_colnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Generate association rules to find relationships between items\u001b[39;00m\n\u001b[0;32m     37\u001b[0m association_rules \u001b[38;5;241m=\u001b[39m association_rules(frequent_itemsets, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlift\u001b[39m\u001b[38;5;124m'\u001b[39m, min_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlxtend\\frequent_patterns\\apriori.py:241\u001b[0m, in \u001b[0;36mapriori\u001b[1;34m(df, min_support, use_colnames, max_len, verbose, low_memory)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_support \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`min_support` must be a positive \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber within the interval `(0, 1]`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m min_support\n\u001b[0;32m    239\u001b[0m     )\n\u001b[1;32m--> 241\u001b[0m \u001b[43mfpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_input_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# DataFrame with SparseArray (pandas >= 0.24)\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:132\u001b[0m, in \u001b[0;36mvalid_input_check\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    127\u001b[0m val \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;28mtuple\u001b[39m(loc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m loc \u001b[38;5;129;01min\u001b[39;00m idxs)]\n\u001b[0;32m    128\u001b[0m s \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe allowed values for a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m are True, False, 0, 1. Found value \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (val)\n\u001b[0;32m    131\u001b[0m )\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(s)\n",
      "\u001b[1;31mValueError\u001b[0m: The allowed values for a DataFrame are True, False, 0, 1. Found value 7"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Perform label encoding for 'category', 'major_flavor', and 'age' columns\n",
    "label_encoder = LabelEncoder()\n",
    "columns_to_label_encode = ['name','category', 'major_flavor', 'age','spicy','creamy','contains_fruits','time','gender','season']\n",
    "for column in columns_to_label_encode:\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Perform clustering to group similar items (categories) together\n",
    "# We'll use KMeans for this example\n",
    "scaler = StandardScaler()\n",
    "X = data.drop(columns=['feedback'])\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "data['category_cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Train a classification model to predict customer feedback based on features\n",
    "X = data.drop(columns=['feedback'])\n",
    "y = data['feedback']\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions to identify items with low feedback ratings\n",
    "data['predicted_feedback'] = model.predict(X)\n",
    "\n",
    "# Find frequent itemsets using association rule mining\n",
    "frequent_itemsets = apriori(data[['category', 'major_flavor', 'age']], min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Generate association rules to find relationships between items\n",
    "association_rules = association_rules(frequent_itemsets, metric='lift', min_threshold=1)\n",
    "\n",
    "# Suggestions for the owner\n",
    "# Find categories with low feedback ratings\n",
    "categories_to_remove = data[data['predicted_feedback'] < 4]['category_cluster'].unique()\n",
    "\n",
    "# Find flavors that are liked in different age groups\n",
    "flavors_by_age_group = data.groupby(['major_flavor', 'age'])['feedback'].mean().reset_index()\n",
    "\n",
    "# Find frequent associations between food items\n",
    "frequent_associations = association_rules[['antecedents', 'consequents', 'lift']]\n",
    "\n",
    "print(\"Categories to remove:\", categories_to_remove)\n",
    "print(\"Flavors liked by age group:\")\n",
    "print(flavors_by_age_group)\n",
    "print(\"Frequent associations between food items:\")\n",
    "print(frequent_associations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109fde2b",
   "metadata": {},
   "source": [
    "1. **Data Loading and Preprocessing**:\n",
    "   - We start by loading the data from the 'data.csv' file using pandas.\n",
    "   - We identify three columns ('category', 'major_flavor', and 'age') that contain categorical data and need to be label encoded (converted from categorical to numerical).\n",
    "   - We use the LabelEncoder from scikit-learn to perform label encoding on these columns.\n",
    "\n",
    "2. **Clustering (KMeans)**:\n",
    "   - Since we have multiple categories in the 'category' column, we want to group similar categories together.\n",
    "   - To do this, we apply KMeans clustering on the numerical features (excluding 'feedback') to group similar items (categories) together.\n",
    "   - We scale the numerical features using StandardScaler to ensure they are on a similar scale before applying KMeans.\n",
    "   - We choose the number of clusters as 3 in this example, but you can adjust this value based on your specific data.\n",
    "\n",
    "3. **Classification (Random Forest)**:\n",
    "   - The objective is to train a classification model to predict customer feedback (ratings) based on the features (columns) in the data.\n",
    "   - We use the RandomForestClassifier from scikit-learn to build the classification model.\n",
    "   - The features (X) are all the columns in the data except for the 'feedback' column, and the target variable (y) is the 'feedback' column.\n",
    "   - We fit the model on the data to learn the patterns and relationships between features and feedback ratings.\n",
    "\n",
    "4. **Making Predictions**:\n",
    "   - After training the classification model, we use it to make predictions on the same dataset.\n",
    "   - We create a new column 'predicted_feedback' and store the predicted feedback ratings for each row in the data.\n",
    "\n",
    "5. **Suggestions for the Owner**:\n",
    "   - We identify categories with low feedback ratings by selecting those rows where the predicted feedback is less than 4 (out of 5).\n",
    "   - We group the data by 'major_flavor' and 'age' to find the average feedback rating for each combination of flavor and age group.\n",
    "   - This provides insights into which flavors are liked more by different age groups.\n",
    "\n",
    "The code provides the owner with suggestions on which categories may need improvement based on low feedback ratings and which flavors are more popular among different age groups. The KMeans clustering helps in organizing categories, and the Random Forest classification helps in predicting feedback ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f4f8066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories to remove: [2 0 1]\n",
      "Flavors liked by age group:\n",
      "    major_flavor  age  feedback\n",
      "0              0   18       4.0\n",
      "1              0   19       5.0\n",
      "2              0   22       4.5\n",
      "3              0   26       2.0\n",
      "4              0   28       3.0\n",
      "..           ...  ...       ...\n",
      "62             3   41       5.0\n",
      "63             3   42       2.0\n",
      "64             3   43       2.0\n",
      "65             3   48       4.0\n",
      "66             3   49       4.0\n",
      "\n",
      "[67 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object' and column not in ['age', 'feedback']:\n",
    "        data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Perform clustering to group similar items (categories) together\n",
    "# We'll use KMeans for this example\n",
    "scaler = StandardScaler()\n",
    "X = data.drop(columns=['feedback'])\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "data['category_cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Train a classification model to predict customer feedback based on features\n",
    "X = data.drop(columns=['feedback'])\n",
    "y = data['feedback']\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions to identify items with low feedback ratings\n",
    "data['predicted_feedback'] = model.predict(X)\n",
    "\n",
    "# Suggestions for the owner\n",
    "# Find categories with low feedback ratings\n",
    "categories_to_remove = data[data['predicted_feedback'] < 4]['category_cluster'].unique()\n",
    "\n",
    "# Find flavors that are liked in different age groups\n",
    "flavors_by_age_group = data.groupby(['major_flavor', 'age'])['feedback'].mean().reset_index()\n",
    "\n",
    "print(\"Categories to remove:\", categories_to_remove)\n",
    "print(\"Flavors liked by age group:\")\n",
    "print(flavors_by_age_group)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
